{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seaborn import countplot,lineplot, barplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a7486339feb9c41500c800f7f5c1a8bb13b5519f"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import base64\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c59a416860ebe4053c9bf222f29304262061d4eb"
   },
   "outputs": [],
   "source": [
    "tr = pd.read_csv('../input/X_train.csv')\n",
    "te = pd.read_csv('../input/X_test.csv')\n",
    "target = pd.read_csv('../input/y_train.csv')\n",
    "ss = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "72dcb5b15e3fd3a08e99cd87d7e0ee505b486dab"
   },
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.atan2(t3, t4)\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "def fe(actual):\n",
    "    new = pd.DataFrame()\n",
    "    actual['total_angular_velocity'] = (actual['angular_velocity_X'] ** 2 + actual['angular_velocity_Y'] ** 2 + actual['angular_velocity_Z'] ** 2) ** 0.5\n",
    "    actual['total_linear_acceleration'] = (actual['linear_acceleration_X'] ** 2 + actual['linear_acceleration_Y'] ** 2 + actual['linear_acceleration_Z'] ** 2) ** 0.5\n",
    "    \n",
    "    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n",
    "    \n",
    "    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n",
    "    nx, ny, nz = [], [], []\n",
    "    for i in range(len(x)):\n",
    "        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n",
    "        nx.append(xx)\n",
    "        ny.append(yy)\n",
    "        nz.append(zz)\n",
    "    \n",
    "    actual['euler_x'] = nx\n",
    "    actual['euler_y'] = ny\n",
    "    actual['euler_z'] = nz\n",
    "    \n",
    "    actual['total_angle'] = (actual['euler_x'] ** 2 + actual['euler_y'] ** 2 + actual['euler_z'] ** 2) ** 5\n",
    "    actual['angle_vs_acc'] = actual['total_angle'] / actual['total_linear_acceleration']\n",
    "    actual['angle_vs_vel'] = actual['total_angle'] / actual['total_angular_velocity']\n",
    "    \n",
    "    def f1(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "    \n",
    "    def f2(x):\n",
    "        return np.mean(np.abs(np.diff(x)))\n",
    "    \n",
    "    for col in actual.columns:\n",
    "        if col in ['row_id', 'series_id', 'measurement_number']:\n",
    "            continue\n",
    "        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n",
    "        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n",
    "        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n",
    "        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n",
    "        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n",
    "        \n",
    "        # Change. 1st order.\n",
    "        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(f2)\n",
    "        \n",
    "        # Change of Change. 2nd order.\n",
    "        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(f1)\n",
    "        \n",
    "        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c83ffc7419624eac709d77efb5b1c517e94dc2cc"
   },
   "outputs": [],
   "source": [
    "tr = fe(tr)\n",
    "te = fe(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3f15093d6371c286132be9e5ec22aed67419a949"
   },
   "outputs": [],
   "source": [
    "train_labels= target['surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "tr.fillna(0, inplace = True)\n",
    "te.fillna(0, inplace = True)\n",
    "tr.replace(-np.inf, 0, inplace = True)\n",
    "tr.replace(np.inf, 0, inplace = True)\n",
    "te.replace(-np.inf, 0, inplace = True)\n",
    "te.replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ebf1636d252dccd867b9bb7fbdec4422dfaae19e"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_label_encoded = le.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "50e6041edcd8186ebd3d79fdaaec5c44fcd95ed5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(tr,train_label_encoded,test_size = 0.33 ,random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "c3772728409411e4c11f73c3b53e8b1d69dd70b8"
   },
   "outputs": [],
   "source": [
    "train_set = lgb.Dataset(train_features, label = train_labels)\n",
    "test_set = lgb.Dataset(test_features, label = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d3c2ad31d0ee5405d16ef11ac9152ff458e0468a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "4f7e0fffe34c3ea017ddea79b4bd168fb2550c3c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=546789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "b677e538aad7f7498fd4660159fff2c2ef07bfa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concrete                  779\n",
       "soft_pvc                  732\n",
       "wood                      607\n",
       "tiled                     514\n",
       "fine_concrete             363\n",
       "hard_tiles_large_space    308\n",
       "soft_tiles                297\n",
       "carpet                    189\n",
       "hard_tiles                 21\n",
       "Name: surface, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['surface'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "3a30a0874dfda1dd6dbfd652933996765392dac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete                  623\n",
      "soft_pvc                  585\n",
      "wood                      485\n",
      "tiled                     411\n",
      "fine_concrete             290\n",
      "hard_tiles_large_space    246\n",
      "soft_tiles                237\n",
      "carpet                    151\n",
      "hard_tiles                 16\n",
      "Name: surface, dtype: int64\n",
      "concrete                  623\n",
      "soft_pvc                  585\n",
      "wood                      485\n",
      "tiled                     411\n",
      "fine_concrete             290\n",
      "hard_tiles_large_space    246\n",
      "soft_tiles                237\n",
      "carpet                    151\n",
      "hard_tiles                 17\n",
      "Name: surface, dtype: int64\n",
      "concrete                  623\n",
      "soft_pvc                  586\n",
      "wood                      486\n",
      "tiled                     411\n",
      "fine_concrete             290\n",
      "hard_tiles_large_space    246\n",
      "soft_tiles                238\n",
      "carpet                    151\n",
      "hard_tiles                 17\n",
      "Name: surface, dtype: int64\n",
      "concrete                  623\n",
      "soft_pvc                  586\n",
      "wood                      486\n",
      "tiled                     411\n",
      "fine_concrete             291\n",
      "hard_tiles_large_space    247\n",
      "soft_tiles                238\n",
      "carpet                    151\n",
      "hard_tiles                 17\n",
      "Name: surface, dtype: int64\n",
      "concrete                  624\n",
      "soft_pvc                  586\n",
      "wood                      486\n",
      "tiled                     412\n",
      "fine_concrete             291\n",
      "hard_tiles_large_space    247\n",
      "soft_tiles                238\n",
      "carpet                    152\n",
      "hard_tiles                 17\n",
      "Name: surface, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(folds.split(tr, target['surface'])):\n",
    "    tr_data = tr.iloc[train_index]\n",
    "#     print(tr_data.head(1))\n",
    "#     series_id = tr_data['series_id']\n",
    "    labels = target.iloc[train_index]\n",
    "    print(labels['surface'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "4a8c09d49adfc4af83ff8b054123e5d980899130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# tr.value_counts\n",
    "target['surface'].value_counts()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "c6ec98d08860725fc32427f5ce9952081a83c38e"
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# random_forest = RandomForestClassifier(n_estimators = 100, random_state = 50)\n",
    "# random_forest.fit(tr, train_labels)\n",
    "# predictions = random_forest.predict_proba(te)[:,1]\n",
    "# predict_class = random_forest.predict(te)\n",
    "# submit_df = pd.DataFrame(te.reset_index()['series_id'],columns=['series_id'])\n",
    "# submit_df['surface']= predict_class\n",
    "# submit_df.to_csv('Sixth_sol_random_forest_feature_eng.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "dd97723305882f62caff4cde8da1d6606cb4c18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "d5b519487da3de97d9a160e6732742df5cbe6c08"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9f27d9505d05a2f202f42552b8291d9ab7854774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(tr, target['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "36dc0f5a827e81a97ce93a28e05e5cb5d7d6d2c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 60,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "d1a88110514e9c27b3710bb1311f973d5b34033f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7803149606299212"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
