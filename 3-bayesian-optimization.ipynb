{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seaborn import countplot,lineplot, barplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "45bf3abc194d6fdb0b8a34cfc5e8b4fdd38c1970"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import base64\n",
    "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8efc94a8f1091ea44f114cc3b6fac1d1be4abfc5"
   },
   "outputs": [],
   "source": [
    "tr = pd.read_csv('../input/X_train.csv')\n",
    "te = pd.read_csv('../input/X_test.csv')\n",
    "target = pd.read_csv('../input/y_train.csv')\n",
    "ss = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d0a0121537e7d91b14cccf9b05b277e16c92b9c8"
   },
   "outputs": [],
   "source": [
    "def quaternion_to_euler(x, y, z, w):\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.atan2(t3, t4)\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "def fe(actual):\n",
    "    new = pd.DataFrame()\n",
    "    actual['total_angular_velocity'] = (actual['angular_velocity_X'] ** 2 + actual['angular_velocity_Y'] ** 2 + actual['angular_velocity_Z'] ** 2) ** 0.5\n",
    "    actual['total_linear_acceleration'] = (actual['linear_acceleration_X'] ** 2 + actual['linear_acceleration_Y'] ** 2 + actual['linear_acceleration_Z'] ** 2) ** 0.5\n",
    "    \n",
    "    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n",
    "    \n",
    "    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n",
    "    nx, ny, nz = [], [], []\n",
    "    for i in range(len(x)):\n",
    "        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n",
    "        nx.append(xx)\n",
    "        ny.append(yy)\n",
    "        nz.append(zz)\n",
    "    \n",
    "    actual['euler_x'] = nx\n",
    "    actual['euler_y'] = ny\n",
    "    actual['euler_z'] = nz\n",
    "    \n",
    "    actual['total_angle'] = (actual['euler_x'] ** 2 + actual['euler_y'] ** 2 + actual['euler_z'] ** 2) ** 5\n",
    "    actual['angle_vs_acc'] = actual['total_angle'] / actual['total_linear_acceleration']\n",
    "    actual['angle_vs_vel'] = actual['total_angle'] / actual['total_angular_velocity']\n",
    "    \n",
    "    def f1(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "    \n",
    "    def f2(x):\n",
    "        return np.mean(np.abs(np.diff(x)))\n",
    "    \n",
    "    for col in actual.columns:\n",
    "        if col in ['row_id', 'series_id', 'measurement_number']:\n",
    "            continue\n",
    "        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n",
    "        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n",
    "        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n",
    "        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n",
    "        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n",
    "        \n",
    "        # Change. 1st order.\n",
    "        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(f2)\n",
    "        \n",
    "        # Change of Change. 2nd order.\n",
    "        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(f1)\n",
    "        \n",
    "        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1e7d99ffecde84e5f373c8e885c9c92f514526b6"
   },
   "outputs": [],
   "source": [
    "tr = fe(tr)\n",
    "te = fe(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "dcd46eeff92e422ead23d0bf5d08d5d31d896868"
   },
   "outputs": [],
   "source": [
    "train_labels= target['surface']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "c3f1a4c5b995e7ba6a931abb41a0db5e1f50f518"
   },
   "outputs": [],
   "source": [
    "tr.fillna(0, inplace = True)\n",
    "te.fillna(0, inplace = True)\n",
    "tr.replace(-np.inf, 0, inplace = True)\n",
    "tr.replace(np.inf, 0, inplace = True)\n",
    "te.replace(-np.inf, 0, inplace = True)\n",
    "te.replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "f72e38ece4a078d1a40def7493b0b4838b4e80bf"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_label_encoded = le.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "78361af62459f3621639f4944882f2fcd50c519a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(tr,train_label_encoded,test_size = 0.33 ,random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_set = lgb.Dataset(train_features, label = train_labels)\n",
    "test_set = lgb.Dataset(test_features, label = test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "934b0e14468d01ee6c5d86101a0666d818051f1b"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a7dce77b2e4eaf0d55b28606ed0766353868bca1"
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5b751ebdc8987453a641047d668968480f1f3d64"
   },
   "outputs": [],
   "source": [
    "x = sample(space)\n",
    "\n",
    "# Conditional logic to assign top-level keys\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "9bc0b688bf7429b591632ee02535d4b29038bcd5"
   },
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "# Create the algorithm\n",
    "tpe_algorithm = tpe.suggest\n",
    "\n",
    "\n",
    "from hyperopt import Trials\n",
    "\n",
    "# Record results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "1b8c5f97cf1a51d3e4a16fdbbe9c8b2248af2fa7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from hyperopt import fmin\n",
    "\n",
    "\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "# best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "#             max_evals = MAX_EVALS)\n",
    "\n",
    "# best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0a3dfc99771902aa270e47a766f66a126f30ed2f"
   },
   "outputs": [],
   "source": [
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top level keys\n",
    "    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "    hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['auc-mean'][-1]\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['auc-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "#     of_connection = open(OUT_FILE, 'a')\n",
    "#     writer = csv.writer(of_connection)\n",
    "#     writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n",
    "#     of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "e033fbd012d3e3d34d58a13ed38f0477785a8c64"
   },
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "a44a792b6c173e2a71d3a0cdcf2d76e98b79dfc0"
   },
   "outputs": [],
   "source": [
    "# best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "#             max_evals = MAX_EVALS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
